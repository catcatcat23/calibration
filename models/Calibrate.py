import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
class _IsoMap(nn.Module):
    """irova:å•è°ƒå›å½’çš„åˆ†æ®µå¸¸æ•°æ˜ å°„ï¼šy = step(x)ã€‚boundaries:[M-1], values:[M]"""
    def __init__(self):
        super().__init__()
        self.register_buffer("boundaries", torch.empty(0))
        self.register_buffer("values", torch.empty(0))

    @torch.no_grad()
    def set_params(self, boundaries: torch.Tensor, values: torch.Tensor):
        self.boundaries = boundaries.detach().float().reshape(-1)
        self.values = values.detach().float().reshape(-1)

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        if self.values.numel() == 0:
            raise RuntimeError("iROVA æ˜ å°„å°šæœªæ‹Ÿåˆï¼ˆvalues ä¸ºç©ºï¼‰")
        idx = torch.searchsorted(self.boundaries, x, right=True)  # [N], èŒƒå›´ 0..M-1
        return self.values[idx]  # é€æ ·æœ¬å–æ‰€åœ¨å°é˜¶çš„å¸¸æ•°

class Calibrate_Model(nn.Module):
    """
    calibrate_method:
      - 'ts'      : æ¸©åº¦ç¼©æ”¾ï¼Œforward è¿”å› logits/T
      - 'ets'     : ETS(ä¸‰ç»„ä»¶)ï¼Œforward è¿”å› log(q) ä½œä¸º "logits"
      - 'ets_pc'  : ETS + æŒ‰ç±»æ¸©åº¦ï¼ˆæ¯ç±»ä¸€ä¸ª Tï¼‰
    éæƒ°æ€§ï¼šé€‰æ‹© ETS æ—¶ç«‹å³åˆ›å»º Î± å‚æ•°ï¼ˆéœ€ä¼ å…¥ç±»åˆ«æ•°ï¼‰
    """
    def __init__(self, model, T=None):
        super().__init__()
        self.model = model
        self.T = nn.Parameter(torch.tensor(1.0 if T is None else T, dtype=torch.float32))

        # ç»Ÿä¸€æ¨¡å¼å¼€å…³ï¼ˆé»˜è®¤ TSï¼‰ï¼Œå¯¹å¤–ä¸€å¾‹â€œåƒ logitsâ€
        self.calib_method = 'ts'
        self._returns_log_prob = False  # æˆ‘ä»¬ç»Ÿä¸€æŠŠè¾“å‡ºå½“ logits ç”¨ï¼ˆETS è¿”å› log(q)ï¼‰

        # ===== ETS ç›¸å…³ï¼ˆéæƒ°æ€§ï¼‰=====
        self._etsm_enabled = False
        self._etsm_per_class = False
        self._etsm_eps = 1e-8
        self._etsm_w_logits = None
        self._etsm_alpha_raw_bos = None
        self._etsm_alpha_raw_bom = None
        self._etsm_init_alpha = 1.0
        # è®°å½•ç±»åˆ«æ•°ï¼Œä¾¿äºæ ¡éªŒ
        self._num_classes_bos = None
        self._num_classes_bom = None
        
        # ===== iROVA ç›¸å…³ =====
        self._irova_enabled = False
        self._irova_use_ts = False     # æ˜¯å¦å…ˆåš TSï¼ˆå³ logits/T å† softmaxï¼‰
        self._irova_eps = 1e-8
        self._irova_bos = None         # nn.ModuleList([_IsoMap]*K_bos)
        self._irova_bom = None         # nn.ModuleList([_IsoMap]*K_bom)
        self._irova_fitted_bos = False
        self._irova_fitted_bom = False


    # ========= ä¸»å…¥å£ï¼šç”± args é©±åŠ¨ï¼Œéæƒ°æ€§åˆ›å»º Î± ========= ğŸ”§
    def set_calibrate_method(self, method: str,
                             per_class: bool = False,
                             init_T: float = 1.0,
                             num_classes_bom: int = None,
                             num_classes_bos: int = None):
        """
        å‚æ•°ï¼š
          method: 'ts' | 'ets' | 'ets_pc'
          per_class: ETS æ˜¯å¦æŒ‰ç±»æ¸©åº¦
          init_T: ETS åˆå§‹ Tï¼ˆÎ±=1/Tï¼‰
          num_classes_bom/bos: å¯¹åº”å¤´çš„ç±»åˆ«æ•°ï¼ˆETS ä¸‹å¿…éœ€ï¼›TS å¯å¿½ç•¥ï¼‰
        """
        method = (method or 'ts').lower()
              # â€¦å…ˆæŠŠ ETS æ ‡è®°æ¸…é›¶â€¦
        self._etsm_enabled = False
        self._returns_log_prob = False
        self._irova_enabled = False
        self._irova_use_ts = False
        if method == 'ts':
            self.calib_method = 'ts'
            self._returns_log_prob = False
            self._etsm_enabled = False
            return
        if method in ('ets', 'ets_pc', 'ets-pc'):
            # ETS / ETS_PC
            if num_classes_bom is None and num_classes_bos is None:
                raise ValueError("ETS éœ€è¦æä¾› num_classes_bom æˆ– num_classes_bosï¼ˆè‡³å°‘ä¸€ä¸ªå¤´çš„ Kï¼‰")

            self._num_classes_bos = num_classes_bos
            self._num_classes_bom = num_classes_bom
            self._etsm_per_class = bool(per_class or method in ('ets_pc','ets-pc'))
            self._etsm_eps = 1e-8
            self._etsm_enabled = True
            self._etsm_init_alpha = 1.0 / max(init_T, 1e-6)

            # ç«‹å³åˆ›å»ºå‚æ•°ï¼ˆéæƒ°æ€§ï¼‰ ğŸ”§
            self._create_ets_params()

            self.calib_method = 'ets_pc' if self._etsm_per_class else 'ets'
            self._returns_log_prob = False  # å¯¹å¤–ä»ç„¶å½“ä½œ logits ç”¨
            return
        
        if method == 'irova_ts':
            self.calib_method = 'irova_ts'
            self._irova_enabled = True
            self._irova_use_ts = True
            self._num_classes_bos = num_classes_bos
            self._num_classes_bom = num_classes_bom
            if num_classes_bos is not None and self._irova_bos is None:
                self._irova_bos = nn.ModuleList([_IsoMap() for _ in range(num_classes_bos)])
            if num_classes_bom is not None and self._irova_bom is None:
                self._irova_bom = nn.ModuleList([_IsoMap() for _ in range(num_classes_bom)])
            return
        
        if method == 'irova':
            self.calib_method = 'irova'
            self._irova_enabled = True
            self._irova_use_ts = False
            self._num_classes_bos = num_classes_bos
            self._num_classes_bom = num_classes_bom
            if num_classes_bos is not None and self._irova_bos is None:
                self._irova_bos = nn.ModuleList([_IsoMap() for _ in range(num_classes_bos)])
            if num_classes_bom is not None and self._irova_bom is None:
                self._irova_bom = nn.ModuleList([_IsoMap() for _ in range(num_classes_bom)])
            return 
        
    def _infer_device(self):
        # å–å·²æœ‰å‚æ•°çš„ deviceï¼›ä¼˜å…ˆéª¨å¹²ï¼Œå…¶æ¬¡ T
        for p in self.model.parameters():
            return p.device
        return self.T.device
    # ========= ç«‹å³åˆ›å»º ETS å‚æ•°ï¼ˆéæƒ°æ€§ï¼‰ ========= ğŸ”§
    def _create_ets_params(self):
        # 3 ä¸ªæ··åˆæƒé‡ï¼ˆsoftmax çº¦æŸï¼‰
        self._etsm_w_logits = nn.Parameter(torch.zeros(3, dtype=torch.float32))
        device = self._infer_device()
        init_raw = float(np.log(np.exp(self._etsm_init_alpha) - 1.0))  # Î± = softplus(raw)+eps
        # bos å¤´
        if self._num_classes_bos is not None:
            if self._etsm_per_class:
                self._etsm_alpha_raw_bos = nn.Parameter(torch.full(
                    (self._num_classes_bos,), init_raw, dtype=torch.float32, device=device))
            else:
                self._etsm_alpha_raw_bos = nn.Parameter(torch.tensor([init_raw], dtype=torch.float32, device=device))
        else:
            self._etsm_alpha_raw_bos = None

        # bom å¤´
        if self._num_classes_bom is not None:
            if self._etsm_per_class:
                self._etsm_alpha_raw_bom = nn.Parameter(torch.full(
                    (self._num_classes_bom,), init_raw, dtype=torch.float32,device=device))
            else:
                self._etsm_alpha_raw_bom = nn.Parameter(torch.tensor([init_raw], dtype=torch.float32,device=device))
        else:
            self._etsm_alpha_raw_bom = None

    # ========= forwardï¼šç»Ÿä¸€è°ƒç”¨ï¼Œä¸åšæƒ°æ€§åˆå§‹åŒ– =========
    def forward(self, img1, img2):
        if self.calib_method.startswith('ets') and self._etsm_enabled:
            return self._forward_ets_as_logits(img1, img2)
        
        if self.calib_method.startswith('ts'):

            # TSï¼šè¿”å› logits / T
            logits_bos, logits_bom = self.model(img1, img2)
            out_bos = None if logits_bos is None else logits_bos / self.T
            out_bom = None if logits_bom is None else logits_bom / self.T
            self._returns_log_prob = False
        if self._irova_enabled:  # è¦†ç›– irova / irova_ts
            return self._forward_irova_as_logits(img1, img2)
        return out_bos, out_bom

    def calibrate_test(self, img1, img2):
        self.eval()
        with torch.no_grad():
            return self(img1, img2)

    # ========= å†»ç»“éª¨å¹²ï¼Œåªå­¦æ ¡å‡†å‚æ•° =========
    def pre_fintune(self):
        for p in self.model.parameters():
            p.requires_grad = False

        if self.calib_method == 'ts':
            self.T.requires_grad = True
        elif self.calib_method.startswith('ets'):
            # ETSï¼šw ä¸ Î± å¯è®­ç»ƒï¼ˆéæƒ°æ€§æ—¶å¿…å®šå·²å­˜åœ¨ï¼‰
            assert self._etsm_w_logits is not None, "ETS å‚æ•°æœªåˆå§‹åŒ–ï¼›è¯·å…ˆ set_calibrate_method(..., num_classes_*)"
            self._etsm_w_logits.requires_grad = True
            if self._etsm_alpha_raw_bos is not None:
                self._etsm_alpha_raw_bos.requires_grad = True
            if self._etsm_alpha_raw_bom is not None:
                self._etsm_alpha_raw_bom.requires_grad = True
            # å¦‚éœ€åŒæ—¶å­¦æ ¡å‡†å…¨å±€ Tï¼Œå¯æ‰“å¼€ï¼š
            # self.T.requires_grad = True
        elif self.calib_method.startswith('irova'):
            # iROVAï¼šT å¯è®­ç»ƒ
            self.T.requires_grad = True
            # iROVA æ˜ å°„ä¸å¯å¾®ï¼Œæ•…ä¸è®­ç»ƒ
            if self._irova_bos is not None:
                for m in self._irova_bos:
                    for p in m.parameters():
                        p.requires_grad = False
            if self._irova_bom is not None:
                for m in self._irova_bom:
                    for p in m.parameters():
                        p.requires_grad = False
    # ========= å…¶ä»–å·¥å…·ï¼ˆä¿æŒä½ åŸæ¥çš„ï¼‰ =========
    def compile_model(self):
        self.model = torch.jit.script(self.model)

    def grid_search_set(self, T_range, dt):
        self.candidate_T_arange = np.arange(T_range[0], T_range[1] + dt, dt)
        self.T_index = 0

    def reflash_T(self):
        assert self.T_index < len(self.candidate_T_arange), "å·²è¶…è¿‡å¯é€‰TèŒƒå›´"
        self.T = nn.Parameter(torch.tensor(self.candidate_T_arange[self.T_index], dtype=torch.float32))

    def reset_index(self, T_idx=None):
        self.T_index = T_idx if T_idx is not None else (self.T_index + 1)

    def __len__(self):
        print(f"å¯é€‰TèŒƒå›´ä¸º: {len(self.candidate_T_arange)}")
        return len(self.candidate_T_arange)

    # ========= ETS è®¡ç®— =========
    def _etsm_softplus_pos(self, x):  # Î±>0
        return F.softplus(x) + self._etsm_eps

    def _etsm_ts_prob(self, p, alpha):
        # p^{alpha} / sum p^{alpha}ï¼Œalpha: æ ‡é‡æˆ– [K]
        if alpha.ndim == 0:
            a = alpha.view(1, 1)
        else:
            a = alpha.view(1, -1)
        p_pow = torch.clamp(p, min=self._etsm_eps) ** a
        return p_pow / p_pow.sum(dim=1, keepdim=True)

    def _forward_ets_as_logits(self, img1, img2):
        """
        ETSï¼š
          logits -> p -> q = w1*TS(p;Î±) + w2*p + w3*uniform
          è¿”å› log(q) ä½œä¸º "logits"ï¼ˆCE/Focal ç›´æ¥å¯ç”¨ï¼‰
        """
        assert self._etsm_enabled, "è¯·å…ˆ set_calibrate_method('ets'/'ets_pc', ...)"
        logits_bos, logits_bom = self.model(img1, img2)
        w = torch.softmax(self._etsm_w_logits, dim=0)  # [3]

        out_bos = None
        if logits_bos is not None:
            if self._num_classes_bos is not None:
                assert logits_bos.shape[1] == self._num_classes_bos, \
                    f"bos ç±»åˆ«æ•°ä¸ä¸€è‡´ï¼šlogits:{logits_bos.shape[1]} vs é…ç½®:{self._num_classes_bos}"
            if self._etsm_alpha_raw_bos is not None:
                alpha_bos = self._etsm_softplus_pos(self._etsm_alpha_raw_bos)
                p = F.softmax(logits_bos, dim=1)
                ts = self._etsm_ts_prob(p, alpha_bos)
                uni = torch.full_like(p, 1.0 / p.shape[1])
                q = w[0] * ts + w[1] * p + w[2] * uni
                out_bos = torch.log(q.clamp_min(self._etsm_eps))
            else:
                out_bos = None  # æœªé…ç½® bos

        out_bom = None
        if logits_bom is not None:
            if self._num_classes_bom is not None:
                assert logits_bom.shape[1] == self._num_classes_bom, \
                    f"bom ç±»åˆ«æ•°ä¸ä¸€è‡´ï¼šlogits:{logits_bom.shape[1]} vs é…ç½®:{self._num_classes_bom}"
            if self._etsm_alpha_raw_bom is not None:
                alpha_bom = self._etsm_softplus_pos(self._etsm_alpha_raw_bom)
                p = F.softmax(logits_bom, dim=1)
                ts = self._etsm_ts_prob(p, alpha_bom)
                uni = torch.full_like(p, 1.0 / p.shape[1])
                q = w[0] * ts + w[1] * p + w[2] * uni
                out_bom = torch.log(q.clamp_min(self._etsm_eps))
            else:
                out_bom = None  # æœªé…ç½® bom

        self._returns_log_prob = False  # å¯¹å¤–å½“ logits
        return out_bos, out_bom
    
      # ===== iROVAï¼šPAV æ‹Ÿåˆä¸€æ¡å•è°ƒå‡½æ•°ï¼Œè¾“å‡ºè¾¹ç•Œä¸å°é˜¶å€¼ =====

    @staticmethod
    def _pav_isotonic_fit(x_np: np.ndarray, y_np: np.ndarray) -> tuple[np.ndarray, np.ndarray]:
        """
        PAV æ‹Ÿåˆå•è°ƒå‡½æ•°ï¼Œè¿”å› (boundaries, values)
        - boundaries: [M-1] åˆ†æ®µç‚¹
        - values: [M] æ¯æ®µçš„å¸¸æ•°å€¼
        è¾“å…¥ï¼šx_npâˆˆ[0,1]^Nï¼ˆè‡ªä¿¡åº¦ï¼‰ï¼Œy_npâˆˆ{0,1}^Nï¼ˆæ˜¯å¦ä¸ºè¯¥ç±»ï¼‰
        è¾“å‡ºï¼šboundaries:[M-1], values:[M]ï¼ˆéé™é˜¶æ¢¯ï¼‰
        """
        x = np.asarray(x_np, dtype=np.float64)
        y = np.asarray(y_np, dtype=np.float64)
        oder = np.argsort(x, kind='mergesort')

        x , y = x[oder], y[oder]
        # åˆå§‹åŒ–
    
        sum_w = np.ones_like(y)
        sum_y = y.copy()
        mean = sum_y / np.maximum(sum_w, 1e-12)

        # æ ˆå®ç° PAV
        sw, sy, sm, L, R = [], [], [], [], []
        for i in range(len(x)):
            sw.append(sum_w[i])
            sy.append(sum_y[i])
            sm.append(mean[i])
            L.append(i)
            R.append(i)
            # åˆå¹¶
            while len(sm) >= 2 and sm[-2] > sm[-1] + 1e-12:
                w2, y2, m2, l2, r2 = sw.pop(), sy.pop(), sm.pop(), L.pop(), R.pop()
                w1, y1, m1, l1, r1 = sw.pop(), sy.pop(), sm.pop(), L.pop(), R.pop()
                w = w1 + w2; yv = y1 + y2; m = yv / max(w, 1e-12)
                sw.append(w); sy.append(yv); sm.append(m); L.append(l1); R.append(r2)
        
        M = len(sm)
        boundaries = []
        for k in range(M - 1):
            b = (x[R[k]] + x[L[k + 1]]) / 2.0
            boundaries.append(b)
        boundaries = np.array(boundaries, dtype=np.float64)
        values = np.clip(np.array(sm, dtype=np.float64), 0.0, 1.0
        )




        return boundaries, values
    

    @torch.no_grad()
    def fit_irova(self, head: str, logits: torch.Tensor, labels: torch.Tensor, use_temperature: bool = None):
        """
        åœ¨éªŒè¯é›†ä¸Šæ‹Ÿåˆ iROVA é˜¶æ¢¯ï¼š
          head: 'bos' æˆ– 'bom'
          logits: [N,K]ï¼ˆè¯¥å¤´çš„ logitsï¼‰
          labels: [N]ï¼ˆ0..K-1ï¼‰
          use_temperature: è‹¥ä¸º Noneï¼Œéšå½“å‰æ¨¡å¼ï¼ˆirova_ts=True, irova=Falseï¼‰
        """
     
        if use_temperature is None:
            use_temperature = self._irova_use_ts

        N, K = logits.shape
        device = logits.device

        if head.lower() == 'bos':
            if self._irova_bos is None:
                self._irova_bos = nn.ModuleList([_IsoMap() for _ in range(K)])
        
        elif head.lower() == 'bom':
            if self._irova_bom is None:
                self._irova_bom = nn.ModuleList([_IsoMap() for _ in range(K)])
        else:
            raise ValueError("head å¿…é¡»ä¸º 'bos' æˆ– 'bom'")
        
        if use_temperature:
            p = F.softmax(logits / self.T, dim=1)
        else:
            p = F.softmax(logits, dim=1)
        y = labels.long().view(-1).detach().cpu().numpy()


        p_np = p.detach().cpu().numpy()
        for k in range(K):
            x_k = p_np[:, k]
            y_k = (y == k).astype(np.float64)
            bnd, val = self._pav_isotonic_fit(x_k, y_k)
            bnd_t = torch.tensor(bnd, dtype=torch.float32, device=device)
            val_t = torch.tensor(val, dtype=torch.float32, device=device)
            if head.lower() == 'bos':
                self._irova_bos[k].set_params(bnd_t, val_t)
            else:
                self._irova_bom[k].set_params(bnd_t, val_t)
        
        if head.lower() == 'bos':
            self._irova_fitted_bos = True

        else:
            self._irova_fitted_bom = True
    
    def _forward_irova_as_logits(self, img1, img2):
        """
        iROVAï¼š
          logits -> p -> q = iROVA(p)
          è¿”å› log(q) ä½œä¸º "logits"ï¼ˆCE/Focal ç›´æ¥å¯ç”¨ï¼‰
        """
        logits_bos, logits_bom = self.model(img1, img2)

        out_bos = None
        if logits_bos is not None and self._irova_bos is not None:
            if self._num_classes_bos is not None:
                assert logits_bos.shape[1] == self._num_classes_bos, \
                    f"bos ç±»åˆ«æ•°ä¸ä¸€è‡´ï¼šlogits:{logits_bos.shape[1]} vs é…ç½®:{self._num_classes_bos}"
                
            if not self._irova_fitted_bos or self._irova_bos is None:
                raise RuntimeError("bos å¤´çš„ iROVA å°šæœªæ‹Ÿåˆï¼Œè¯·å…ˆè°ƒç”¨ fit_irova('bos', ...)")
            

            p = F.softmax(logits_bos / self.T if self._irova_use_ts else logits_bos, dim=1)
            qs = [self._irova_bos[k](p[:, k]) for k in range(logits_bos.shape[1])]
            q_tilde = torch.stack(qs, dim=1)
            denom = q_tilde.sum(dim=1, keepdim=True).clamp_min(self._irova_eps)
            q = q_tilde / denom
            out_bos = torch.log(q.clamp_min(self._irova_eps))

        out_bom = None
        if logits_bom is not None and self._irova_bom is not None:
            if self._num_classes_bom is not None:
                assert logits_bom.shape[1] == self._num_classes_bom, \
                    f"bom ç±»åˆ«æ•°ä¸ä¸€è‡´ï¼šlogits:{logits_bom.shape[   1]} vs é…ç½®:{self._num_classes_bom}"
            if not self._irova_fitted_bom or self._irova_bom is None:
                raise RuntimeError("bom å¤´çš„ iROVA å°šæœªæ‹Ÿåˆï¼Œè¯·å…ˆè°ƒç”¨ fit_irova('bom', ...)")
            
            p = F.softmax(logits_bom / self.T if self._irova_use_ts else logits_bom, dim=1)
            qs = [self._irova_bom[k](p[:, k]) for k in range(logits_bom.shape[1])]
            q_tilde = torch.stack(qs, dim=1)
            denom = q_tilde.sum(dim=1, keepdim=True).clamp_min(self._irova_eps)
            q = q_tilde / denom
            out_bom = torch.log(q.clamp_min(self._irova_eps))
            
        self._returns_log_prob = False  # å¯¹å¤–å½“ logits
        return out_bos, out_bom

        

# import torch
# import torch.nn as nn
# import numpy as np

# class TemperatureCalibrator(nn.Module):
#     """
#     é€šç”¨æ¸©åº¦ç¼©æ”¾æ ¡å‡†å±‚ï¼š
#     - mode='learn'ï¼šå­¦ä¹ ï¼ˆå¯å¾®ï¼‰ï¼ŒT>0 é€šè¿‡ softplus çº¦æŸ
#     - mode='grid' ï¼šç½‘æ ¼æœç´¢ï¼ˆä¸å¯å¾®ï¼‰ï¼Œå†…éƒ¨ç»´æŠ¤å€™é€‰ T åˆ—è¡¨å¹¶é€ä¸ªå–å€¼
#     - æ”¯æŒä¸¤ä¸ªå¤´ï¼ˆbos/bomï¼‰å„è‡ªæ‹¥æœ‰ Tï¼Œä¹Ÿå¯é€‰æ‹©å…±äº«
#     """
#     def __init__(self, model, share_T=False, init_T=1.0, mode='learn', eps=1e-6):
#         super().__init__()
#         self.model = model
#         self.mode = mode
#         self.share_T = share_T
#         self.eps = eps

#         # ä»¥ u å‚æ•°åŒ–ï¼šT = softplus(u) + eps ä»¥ä¿è¯ T>0
#         init_u = np.log(np.exp(init_T - eps) - 1.0) if init_T > eps else 0.0
#         init_u = float(init_u)

#         if share_T:
#             self.u_shared = nn.Parameter(torch.tensor([init_u], dtype=torch.float32))
#             self.u_bos = None
#             self.u_bom = None
#         else:
#             self.u_shared = None
#             self.u_bos = nn.Parameter(torch.tensor([init_u], dtype=torch.float32))
#             self.u_bom = nn.Parameter(torch.tensor([init_u], dtype=torch.float32))

#         # grid æ¨¡å¼ç›¸å…³
#         self._grid_vals_bos = None
#         self._grid_vals_bom = None
#         self._grid_idx = 0

#     def _softplus_T(self, u):
#         return torch.nn.functional.softplus(u) + self.eps  # æ ‡é‡ Tensor

#     def _get_Ts(self):
#         """è¿”å›å½“å‰ bos/bom çš„æ ‡é‡æ¸©åº¦ï¼ˆTensorï¼‰ï¼Œæ ¹æ®æ˜¯å¦å…±äº«å†³å®šã€‚"""
#         if self.share_T:
#             T = self._softplus_T(self.u_shared)
#             return T, T
#         else:
#             T_bos = self._softplus_T(self.u_bos)
#             T_bom = self._softplus_T(self.u_bom)
#             return T_bos, T_bom

#     @torch.no_grad()
#     def compile_model(self, try_script=False):
#         if try_script:
#             try:
#                 self.model = torch.jit.script(self.model)
#             except Exception:
#                 # æŒ‰éœ€é™çº§æˆ–å¿½ç•¥
#                 pass

#     def forward(self, img1, img2):
#         logits_bos, logits_bom = self.model(img1, img2)

#         if self.mode == 'learn':
#             # å¯å¾®å­¦ä¹ ï¼šä½¿ç”¨ softplus(u) çš„å½“å‰å€¼
#             T_bos, T_bom = self._get_Ts()
#         elif self.mode == 'grid':
#             # ç½‘æ ¼æœç´¢ï¼šä»é¢„å…ˆè®¾å¥½çš„å€™é€‰è¡¨é‡Œè¯»å–ï¼ˆå¸¸é‡ï¼Œä¸éœ€è¦æ¢¯åº¦ï¼‰
#             assert (self._grid_vals_bos is not None) and (self._grid_vals_bom is not None), \
#                 "è¯·å…ˆè°ƒç”¨ set_grid(start, stop, num) è®¾å®šå€™é€‰ T"
#             T_bos = torch.tensor([self._grid_vals_bos[self._grid_idx]], 
#                                  dtype=torch.float32, device=logits_bos.device if logits_bos is not None else None)
#             T_bom = torch.tensor([self._grid_vals_bom[self._grid_idx]], 
#                                  dtype=torch.float32, device=logits_bom.device if logits_bom is not None else None)
#         else:
#             raise ValueError(f"Unknown mode: {self.mode}")

#         out_bos = logits_bos / T_bos if logits_bos is not None else None
#         out_bom = logits_bom / T_bom if logits_bom is not None else None
#         return out_bos, out_bom

#     # ====== learn æ¨¡å¼ä¸‹çš„ä¾¿æ·æ–¹æ³• ======
#     def freeze_backbone(self):
#         for p in self.model.parameters():
#             p.requires_grad = False
#         # ä»…æ¸©åº¦ç›¸å…³å‚æ•°å‚ä¸è®­ç»ƒ
#         if self.share_T:
#             self.u_shared.requires_grad = True
#         else:
#             self.u_bos.requires_grad = True
#             self.u_bom.requires_grad = True

#     def temperatures(self):
#         """è¿”å›å½“å‰æ•°å€¼åŒ–åçš„ (T_bos, T_bom)ï¼Œç”¨äºæ‰“å°/è®°å½•ã€‚"""
#         with torch.no_grad():
#             if self.share_T:
#                 T = self._softplus_T(self.u_shared).item()
#                 return T, T
#             else:
#                 return self._softplus_T(self.u_bos).item(), self._softplus_T(self.u_bom).item()

#     # ====== grid æ¨¡å¼ä¸‹çš„ä¾¿æ·æ–¹æ³• ======
#     def set_grid(self, start=0.5, stop=3.0, num=26, share_values=True):
#         """
#         è®¾å®šå€™é€‰ T åˆ—è¡¨ã€‚ä½¿ç”¨ linspace æ›´ç¨³å¦¥ã€‚
#         - share_values=Trueï¼šä¸¤ä¸ªå¤´ç”¨åŒä¸€ç»„å€™é€‰ï¼›å¦åˆ™å¯åˆ†åˆ«è®¾ç½®ã€‚
#         """
#         vals = np.linspace(start, stop, num).astype(np.float32)
#         self._grid_vals_bos = vals
#         self._grid_vals_bom = vals if share_values else vals.copy()
#         self._grid_idx = 0

#     def next_T(self):
#         """
#         è¿›å…¥ä¸‹ä¸€ç»„å€™é€‰ Tï¼ˆä»… grid æ¨¡å¼ä½¿ç”¨ï¼‰ã€‚
#         è¿”å› False è¡¨ç¤ºå·²ç”¨å°½ã€‚
#         """
#         if self.mode != 'grid':
#             return False
#         self._grid_idx += 1
#         if self._grid_vals_bos is None:
#             return False
#         return self._grid_idx < len(self._grid_vals_bos)

#     def grid_len(self):
#         return 0 if self._grid_vals_bos is None else len(self._grid_vals_bos)
